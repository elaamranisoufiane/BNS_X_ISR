{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**import dataset**","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/elaamranisoufiane/BNS_1024_test.git","metadata":{"execution":{"iopub.status.busy":"2023-06-23T17:48:07.779278Z","iopub.execute_input":"2023-06-23T17:48:07.779678Z","iopub.status.idle":"2023-06-23T17:48:18.670653Z","shell.execute_reply.started":"2023-06-23T17:48:07.779591Z","shell.execute_reply":"2023-06-23T17:48:18.669467Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'BNS_1024_test'...\nremote: Enumerating objects: 164, done.\u001b[K\nremote: Total 164 (delta 0), reused 0 (delta 0), pack-reused 164\u001b[K\nReceiving objects: 100% (164/164), 111.35 MiB | 24.28 MiB/s, done.\nResolving deltas: 100% (10/10), done.\nUpdating files: 100% (612/612), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\n\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\nfrom tensorflow.keras.models import Model\nfrom matplotlib import pyplot as plt\nimport matplotlib.image as mpimg\n\n ","metadata":{"execution":{"iopub.status.busy":"2023-06-23T17:52:49.970044Z","iopub.execute_input":"2023-06-23T17:52:49.970666Z","iopub.status.idle":"2023-06-23T17:52:49.978539Z","shell.execute_reply.started":"2023-06-23T17:52:49.970626Z","shell.execute_reply":"2023-06-23T17:52:49.977432Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**performance metrics**\n","metadata":{}},{"cell_type":"code","source":"def iou(y_true, y_pred):\n    def f(y_true, y_pred):\n        intersection = (y_true * y_pred).sum()\n        union = y_true.sum() + y_pred.sum() - intersection\n        x = (intersection + 1e-15) / (union + 1e-15)\n        x = x.astype(np.float32)\n        return x\n    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n\nsmooth = 1e-15\ndef dice_coef(y_true, y_pred):\n    y_true = tf.keras.layers.Flatten()(y_true)\n    y_pred = tf.keras.layers.Flatten()(y_pred)\n    intersection = tf.reduce_sum(y_true * y_pred)\n    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    return 1.0 - dice_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T17:52:53.862754Z","iopub.execute_input":"2023-06-23T17:52:53.863138Z","iopub.status.idle":"2023-06-23T17:52:53.873336Z","shell.execute_reply.started":"2023-06-23T17:52:53.863103Z","shell.execute_reply":"2023-06-23T17:52:53.872287Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Our Model**\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\nfrom tensorflow.keras.models import Model\n\ndef conv_block(inputs, num_filters):\n    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    return x\n\ndef encoder_block(inputs, num_filters):\n    s = conv_block(inputs, num_filters)\n    p = MaxPool2D((2, 2))(s)\n    return s, p\n\ndef decoder_block(inputs, skip_features, num_filters):\n    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n    x = Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters)\n    return x\n\ndef build_unet(input_shape):\n    \"\"\" Input layer \"\"\"\n    inputs = Input(input_shape)\n\n    \"\"\" Encoder \"\"\"\n    s1, p1 = encoder_block(inputs, 32)\n    s2, p2 = encoder_block(p1, 64)\n    s3, p3 = encoder_block(p2, 128)\n    s4, p4 = encoder_block(p3, 256)\n    #add layer\n    s5, p5 = encoder_block(p4, 512)\n    \n\n    \"\"\" Bottleneck \"\"\"\n    b1 = conv_block(p5, 1024)\n\n    \"\"\" Decoder \"\"\"\n    #add layer\n    d0 = decoder_block(b1, s5, 512)\n    \n    d1 = decoder_block(d0, s4, 256)\n    d2 = decoder_block(d1, s3, 128)\n    d3 = decoder_block(d2, s2, 64)\n    d4 = decoder_block(d3, s1, 32)\n\n    \"\"\" Output layer \"\"\"\n    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n\n    model = Model(inputs, outputs, name=\"UNET\")\n    return model\n\nif __name__ == \"__main__\":\n    model = build_unet((256, 256, 3))\n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-23T17:52:56.327093Z","iopub.execute_input":"2023-06-23T17:52:56.327789Z","iopub.status.idle":"2023-06-23T17:52:56.866182Z","shell.execute_reply.started":"2023-06-23T17:52:56.327750Z","shell.execute_reply":"2023-06-23T17:52:56.865217Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Model: \"UNET\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d_23 (Conv2D)              (None, 256, 256, 32) 896         input_2[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_22 (BatchNo (None, 256, 256, 32) 128         conv2d_23[0][0]                  \n__________________________________________________________________________________________________\nactivation_22 (Activation)      (None, 256, 256, 32) 0           batch_normalization_22[0][0]     \n__________________________________________________________________________________________________\nconv2d_24 (Conv2D)              (None, 256, 256, 32) 9248        activation_22[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_23 (BatchNo (None, 256, 256, 32) 128         conv2d_24[0][0]                  \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 256, 256, 32) 0           batch_normalization_23[0][0]     \n__________________________________________________________________________________________________\nmax_pooling2d_5 (MaxPooling2D)  (None, 128, 128, 32) 0           activation_23[0][0]              \n__________________________________________________________________________________________________\nconv2d_25 (Conv2D)              (None, 128, 128, 64) 18496       max_pooling2d_5[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_24 (BatchNo (None, 128, 128, 64) 256         conv2d_25[0][0]                  \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 128, 128, 64) 0           batch_normalization_24[0][0]     \n__________________________________________________________________________________________________\nconv2d_26 (Conv2D)              (None, 128, 128, 64) 36928       activation_24[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_25 (BatchNo (None, 128, 128, 64) 256         conv2d_26[0][0]                  \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 128, 128, 64) 0           batch_normalization_25[0][0]     \n__________________________________________________________________________________________________\nmax_pooling2d_6 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_25[0][0]              \n__________________________________________________________________________________________________\nconv2d_27 (Conv2D)              (None, 64, 64, 128)  73856       max_pooling2d_6[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_26 (BatchNo (None, 64, 64, 128)  512         conv2d_27[0][0]                  \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 64, 64, 128)  0           batch_normalization_26[0][0]     \n__________________________________________________________________________________________________\nconv2d_28 (Conv2D)              (None, 64, 64, 128)  147584      activation_26[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_27 (BatchNo (None, 64, 64, 128)  512         conv2d_28[0][0]                  \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 64, 64, 128)  0           batch_normalization_27[0][0]     \n__________________________________________________________________________________________________\nmax_pooling2d_7 (MaxPooling2D)  (None, 32, 32, 128)  0           activation_27[0][0]              \n__________________________________________________________________________________________________\nconv2d_29 (Conv2D)              (None, 32, 32, 256)  295168      max_pooling2d_7[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_28 (BatchNo (None, 32, 32, 256)  1024        conv2d_29[0][0]                  \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 32, 32, 256)  0           batch_normalization_28[0][0]     \n__________________________________________________________________________________________________\nconv2d_30 (Conv2D)              (None, 32, 32, 256)  590080      activation_28[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_29 (BatchNo (None, 32, 32, 256)  1024        conv2d_30[0][0]                  \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 32, 32, 256)  0           batch_normalization_29[0][0]     \n__________________________________________________________________________________________________\nmax_pooling2d_8 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_29[0][0]              \n__________________________________________________________________________________________________\nconv2d_31 (Conv2D)              (None, 16, 16, 512)  1180160     max_pooling2d_8[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_30 (BatchNo (None, 16, 16, 512)  2048        conv2d_31[0][0]                  \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 16, 16, 512)  0           batch_normalization_30[0][0]     \n__________________________________________________________________________________________________\nconv2d_32 (Conv2D)              (None, 16, 16, 512)  2359808     activation_30[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_31 (BatchNo (None, 16, 16, 512)  2048        conv2d_32[0][0]                  \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 16, 16, 512)  0           batch_normalization_31[0][0]     \n__________________________________________________________________________________________________\nmax_pooling2d_9 (MaxPooling2D)  (None, 8, 8, 512)    0           activation_31[0][0]              \n__________________________________________________________________________________________________\nconv2d_33 (Conv2D)              (None, 8, 8, 1024)   4719616     max_pooling2d_9[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_32 (BatchNo (None, 8, 8, 1024)   4096        conv2d_33[0][0]                  \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_32[0][0]     \n__________________________________________________________________________________________________\nconv2d_34 (Conv2D)              (None, 8, 8, 1024)   9438208     activation_32[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_33 (BatchNo (None, 8, 8, 1024)   4096        conv2d_34[0][0]                  \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_33[0][0]     \n__________________________________________________________________________________________________\nconv2d_transpose_5 (Conv2DTrans (None, 16, 16, 512)  2097664     activation_33[0][0]              \n__________________________________________________________________________________________________\nconcatenate_5 (Concatenate)     (None, 16, 16, 1024) 0           conv2d_transpose_5[0][0]         \n                                                                 activation_31[0][0]              \n__________________________________________________________________________________________________\nconv2d_35 (Conv2D)              (None, 16, 16, 512)  4719104     concatenate_5[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_34 (BatchNo (None, 16, 16, 512)  2048        conv2d_35[0][0]                  \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 16, 16, 512)  0           batch_normalization_34[0][0]     \n__________________________________________________________________________________________________\nconv2d_36 (Conv2D)              (None, 16, 16, 512)  2359808     activation_34[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_35 (BatchNo (None, 16, 16, 512)  2048        conv2d_36[0][0]                  \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 16, 16, 512)  0           batch_normalization_35[0][0]     \n__________________________________________________________________________________________________\nconv2d_transpose_6 (Conv2DTrans (None, 32, 32, 256)  524544      activation_35[0][0]              \n__________________________________________________________________________________________________\nconcatenate_6 (Concatenate)     (None, 32, 32, 512)  0           conv2d_transpose_6[0][0]         \n                                                                 activation_29[0][0]              \n__________________________________________________________________________________________________\nconv2d_37 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate_6[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_36 (BatchNo (None, 32, 32, 256)  1024        conv2d_37[0][0]                  \n__________________________________________________________________________________________________\nactivation_36 (Activation)      (None, 32, 32, 256)  0           batch_normalization_36[0][0]     \n__________________________________________________________________________________________________\nconv2d_38 (Conv2D)              (None, 32, 32, 256)  590080      activation_36[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_37 (BatchNo (None, 32, 32, 256)  1024        conv2d_38[0][0]                  \n__________________________________________________________________________________________________\nactivation_37 (Activation)      (None, 32, 32, 256)  0           batch_normalization_37[0][0]     \n__________________________________________________________________________________________________\nconv2d_transpose_7 (Conv2DTrans (None, 64, 64, 128)  131200      activation_37[0][0]              \n__________________________________________________________________________________________________\nconcatenate_7 (Concatenate)     (None, 64, 64, 256)  0           conv2d_transpose_7[0][0]         \n                                                                 activation_27[0][0]              \n__________________________________________________________________________________________________\nconv2d_39 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_7[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_38 (BatchNo (None, 64, 64, 128)  512         conv2d_39[0][0]                  \n__________________________________________________________________________________________________\nactivation_38 (Activation)      (None, 64, 64, 128)  0           batch_normalization_38[0][0]     \n__________________________________________________________________________________________________\nconv2d_40 (Conv2D)              (None, 64, 64, 128)  147584      activation_38[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_39 (BatchNo (None, 64, 64, 128)  512         conv2d_40[0][0]                  \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 64, 64, 128)  0           batch_normalization_39[0][0]     \n__________________________________________________________________________________________________\nconv2d_transpose_8 (Conv2DTrans (None, 128, 128, 64) 32832       activation_39[0][0]              \n__________________________________________________________________________________________________\nconcatenate_8 (Concatenate)     (None, 128, 128, 128 0           conv2d_transpose_8[0][0]         \n                                                                 activation_25[0][0]              \n__________________________________________________________________________________________________\nconv2d_41 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_8[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_40 (BatchNo (None, 128, 128, 64) 256         conv2d_41[0][0]                  \n__________________________________________________________________________________________________\nactivation_40 (Activation)      (None, 128, 128, 64) 0           batch_normalization_40[0][0]     \n__________________________________________________________________________________________________\nconv2d_42 (Conv2D)              (None, 128, 128, 64) 36928       activation_40[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_41 (BatchNo (None, 128, 128, 64) 256         conv2d_42[0][0]                  \n__________________________________________________________________________________________________\nactivation_41 (Activation)      (None, 128, 128, 64) 0           batch_normalization_41[0][0]     \n__________________________________________________________________________________________________\nconv2d_transpose_9 (Conv2DTrans (None, 256, 256, 32) 8224        activation_41[0][0]              \n__________________________________________________________________________________________________\nconcatenate_9 (Concatenate)     (None, 256, 256, 64) 0           conv2d_transpose_9[0][0]         \n                                                                 activation_23[0][0]              \n__________________________________________________________________________________________________\nconv2d_43 (Conv2D)              (None, 256, 256, 32) 18464       concatenate_9[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_42 (BatchNo (None, 256, 256, 32) 128         conv2d_43[0][0]                  \n__________________________________________________________________________________________________\nactivation_42 (Activation)      (None, 256, 256, 32) 0           batch_normalization_42[0][0]     \n__________________________________________________________________________________________________\nconv2d_44 (Conv2D)              (None, 256, 256, 32) 9248        activation_42[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_43 (BatchNo (None, 256, 256, 32) 128         conv2d_44[0][0]                  \n__________________________________________________________________________________________________\nactivation_43 (Activation)      (None, 256, 256, 32) 0           batch_normalization_43[0][0]     \n__________________________________________________________________________________________________\nconv2d_45 (Conv2D)              (None, 256, 256, 1)  33          activation_43[0][0]              \n==================================================================================================\nTotal params: 31,118,561\nTrainable params: 31,106,529\nNon-trainable params: 12,032\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nimport numpy as np\nimport cv2\nfrom glob import glob\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import Recall, Precision\nfrom sklearn.model_selection import KFold\nfrom tqdm import tqdm\nimport pandas as pd\n\n#import build_unet\n#import dice_coef, iou\n \nfrom tensorflow.keras.utils import CustomObjectScope\nfrom sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n\n\n# input image size\nH = 1024\nW = 1024\n\n\n# create directory and gives the path\ndef create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\n\ndef shuffling(x, y):\n    x, y = shuffle(x, y, random_state=42)\n\n\ndef read_image(path):\n    path = path.decode()\n    x = cv2.imread(path, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (W, H))\n    x = x / 255.0\n    x = x.astype(np.float32)\n    return x\n\n\ndef read_mask(path):\n    path = path.decode()\n    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, (W, H))\n    x = x / 255.0\n    x = x.astype(np.float32)\n    x = np.expand_dims(x, axis=-1)\n    return x\n\n\ndef tf_parse(x, y):\n    def _parse(x, y):\n        x = read_image(x)\n        y = read_mask(y)\n        return x, y\n\n    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n    x.set_shape([H, W, 3])\n    y.set_shape([H, W, 1])\n    return x, y\n\n\n\ndef tf_dataset(X, Y, batch=8):\n    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n    dataset = dataset.map(tf_parse)\n    dataset = dataset.batch(batch)\n    dataset = dataset.prefetch(10)\n    return dataset\n\n##########################################\n\ndef create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\n\ndef read_image1(path):\n    x = cv2.imread(path, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (W, H))\n    ori_x = x\n    x = x / 255.0\n    x = x.astype(np.float32)\n    x = np.expand_dims(x, axis=0)  ## (1, 256, 256, 3)\n    return ori_x, x\n\n\ndef read_mask1(path):\n    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, (W, H))\n    ori_x = x\n    x = x / 255.0\n    x = x > 0.5\n    x = x.astype(np.int32)\n    return ori_x, x\n\ndef save_result(ori_x, ori_y, y_pred, save_path):\n    line = np.ones((H, 10, 3)) * 255\n\n    ori_y = np.expand_dims(ori_y, axis=-1)  ## (256, 256, 1)\n    ori_y = np.concatenate([ori_y, ori_y, ori_y], axis=-1)  ## (256, 256, 3)\n\n    y_pred = np.expand_dims(y_pred, axis=-1)\n    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1) * 255.0\n\n    cat_images = np.concatenate([ori_x, line, ori_y, line, y_pred], axis=1)\n    cv2.imwrite(save_path, cat_images)\n\ndef load_data(path, split=0.49):\n    images = sorted(glob(os.path.join(path, \"images\", \"*.png\")))\n    masks = sorted(glob(os.path.join(path, \"masks\", \"*.png\")))\n    size = int(len(images) * split)\n\n    train_x = images\n    train_y =masks\n    valid_x=train_x\n    valid_y=train_y\n\n\n    test_x= train_x\n    test_y=train_y\n    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T17:55:00.849151Z","iopub.execute_input":"2023-06-23T17:55:00.849813Z","iopub.status.idle":"2023-06-23T17:55:00.884838Z","shell.execute_reply.started":"2023-06-23T17:55:00.849757Z","shell.execute_reply":"2023-06-23T17:55:00.883450Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# * # **training part**","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    \"\"\" Seeding \"\"\"\n    np.random.seed(42)\n    tf.random.set_seed(42)\n    # create a file in the same ocation\n    create_dir('files')\n    \"\"\" Hyperparaqmeters \"\"\"\n    batch_size = 8\n    lr = 1e-4  ## 0.0001\n    num_epochs = 260\n    model_path = \"files/model.h5\"\n    csv_path = \"files/data.csv\"\n    create_dir(\"results\")\n    \"\"\" Dataset \"\"\"\n    #dataset_path = \"./DBA\"\n    # colab\n    # dataset_path = \"/content/U-Net-for-Nuclei-Semantic-Segmentation/DSB\"\n    # kuggle\n    dataset_path = \"./2018CompDatasetNormClean\"\n    ##########################\n    \n    # Define per-fold score container\n    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(dataset_path)\n    '''\n    train_x = pd.DataFrame(train_x)\n    test_x = pd.DataFrame(test_x)\n    train_x = pd.concat([train_x, test_x]) \n    \n    train_y = pd.DataFrame(train_y)\n    test_y = pd.DataFrame(test_y)\n    train_y = pd.concat([train_y, test_y]) \n    '''\n    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n    print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n    print(f\"Test: {len(test_x)} - {len(test_y)}\")\n    \n    acc_per_fold = []\n    loss_per_fold = []\n    acc_per_fold = []\n    f1_value_per_fold = []\n    jac_value_per_fold = []\n    recall_value_per_fold = []\n    precision_value_per_fold = []\n  \n    \n    num_folds=4\n    # Define the K-fold Cross Validator\n    kfold = KFold(n_splits=num_folds, shuffle=True)\n    # K-fold Cross Validation model evaluation\n    fold_no = 1\n    for train, test in kfold.split(train_x, train_y):\n        print(f'Training for fold {fold_no} ...')\n        test_x1=[]\n        test_y1=[]\n        for test_i in test:\n            test_x1.append(train_x[test_i])\n            test_y1.append(train_y[test_i])\n        train_x1=[]\n        train_y1=[]\n        \n        for train_i in train:\n            train_x1.append(train_x[train_i])\n            train_y1.append(train_y[train_i])\n        #fold_no = fold_no + 1\n        \n        \n        #(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(dataset_path)\n        #(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(dataset_path) \n        # Generate a print\n        print('------------------------------------------------------------------------')\n        print(f'Training for fold {fold_no} ...')\n        #train_x1, train_y1 = shuffle(train_x1, train_y1)\n        print(f\"Train: {len(train_x1)} - {len(train_y1)}\")\n        print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n        print(f\"Test: {len(test_x1)} - {len(test_y1)}\")\n        train_dataset = tf_dataset(train_x1, train_y1, batch=batch_size)\n        valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n        train_steps = (len(train_x1) // batch_size)\n        valid_steps = (len(valid_x) // batch_size)\n        if len(train_x1) % batch_size != 0:\n            train_steps += 1\n        #if len(valid_x) % batch_size != 0:\n            #valid_steps += 1\n\n        for x, y in valid_dataset:\n            print(x.shape, y.shape)\n            break\n        \"\"\" build the model with U-Net network archtecture \"\"\"\n        model = build_unet((H, W, 3))\n        metrics = [\"accuracy\", dice_coef, iou, Recall(), Precision()]\n        model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr), metrics=metrics)\n        callbacks = [\n            ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n            CSVLogger(csv_path),\n            # EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n        ]\n        history = model.fit(\n            train_dataset,\n            epochs=num_epochs,\n            validation_data=valid_dataset,\n            steps_per_epoch=train_steps,\n            validation_steps=valid_steps,\n            callbacks=callbacks,\n            shuffle=False\n        )\n        fold_no = fold_no + 1\n        ### evaluation\n        #(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(dataset_path)\n        \"\"\" Load Model \"\"\"\n        with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef}):\n            model = tf.keras.models.load_model(model_path)\n            #model.summary()\n        \"\"\" Prediction and metrics values \"\"\"\n        SCORE = []\n        print(f'test image : {test_x1[1]}')\n        for x, y in tqdm(zip(test_x1, test_y1), total=len(test_x1)):\n            name = x.split(\"/\")[-1]\n            \n            \"\"\" Reading the image and mask \"\"\"\n            ori_x, x = read_image1(x)\n            ori_y, y = read_mask1(y)\n            \"\"\" Prediction \"\"\"\n            y_pred = model.predict(x)[0] > 0.5\n            y_pred = np.squeeze(y_pred, axis=-1)\n            y_pred = y_pred.astype(np.int32)\n            \n            save_path = f\"results/{name}\"\n            save_result(ori_x, ori_y, y_pred, save_path)\n            \n            \"\"\" Flattening the numpy arrays. \"\"\"\n            y = y.flatten()\n            y_pred = y_pred.flatten()\n            \n            \"\"\" Calculating metrics values \"\"\"\n            acc_value = accuracy_score(y, y_pred)\n            f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n            jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n            recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n            precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n            SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n           \n    \n        \n            \"\"\" Metrics values \"\"\"\n        print(\"eval metrics\")\n        score = [s[1:] for s in SCORE]\n        score = np.mean(score, axis=0)\n        print(f\"Accuracy: {score[0]:0.5f}\")\n        print(f\"F1: {score[1]:0.5f}\")\n        print(f\"Jaccard: {score[2]:0.5f}\")\n        print(f\"Recall: {score[3]:0.5f}\")\n        print(f\"Precision: {score[4]:0.5f}\")\n        \n        \"\"\" save the results  \"\"\"\n        acc_per_fold.append(score[0])\n        f1_value_per_fold.append(score[1])\n        jac_value_per_fold.append(score[2])\n        recall_value_per_fold.append(score[3])\n        precision_value_per_fold.append(score[4])\n           \n\n        \"\"\" Saving all the results \"\"\"\n        df = pd.DataFrame(SCORE, columns=[\"Image\", \"Accuracy\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n        df.to_csv(\"files/score.csv\")\n\n\"\"\" final metrics\"\"\"\n\nprint(f\"Accuracy: {acc_per_fold}\")\nprint(f\"F1: {f1_value_per_fold}\")\nprint(f\"Jaccard: {jac_value_per_fold}\")\nprint(f\"Recall: {recall_value_per_fold}\")\nprint(f\"Precision: {precision_value_per_fold}\")\n        \n    ##########################","metadata":{"execution":{"iopub.status.busy":"2023-02-16T18:33:28.319372Z","iopub.execute_input":"2023-02-16T18:33:28.320197Z","iopub.status.idle":"2023-02-16T20:15:23.227029Z","shell.execute_reply.started":"2023-02-16T18:33:28.320155Z","shell.execute_reply":"2023-02-16T20:15:23.225915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Accuracy: {np.ceil(np.mean(acc_per_fold)*10000)/100}%\")\nprint(f\"F1: {np.ceil(np.mean(f1_value_per_fold)*10000)/100}%\")\nprint(f\"Jaccard: {np.ceil(np.mean(jac_value_per_fold)*10000)/100}%\")\nprint(f\"Recall: {np.ceil(np.mean(recall_value_per_fold)*10000)/100}%\")\nprint(f\"Precision: {np.ceil(np.mean(precision_value_per_fold)*10000)/100}%\")","metadata":{"execution":{"iopub.status.busy":"2023-02-16T20:15:23.228937Z","iopub.execute_input":"2023-02-16T20:15:23.229893Z","iopub.status.idle":"2023-02-16T20:15:23.238966Z","shell.execute_reply.started":"2023-02-16T20:15:23.229849Z","shell.execute_reply":"2023-02-16T20:15:23.237433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    '''\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(loss) + 1)\n    plt.plot(epochs, loss, 'y', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.savefig('loss.png')\n    plt.show()\n    #plt.imshow(mpimg.imread('./loss.png'))\n\n    accu = history.history['accuracy']\n    val_accu = history.history['val_accuracy']\n    epochs = range(1, len(accu) + 1)\n    plt.plot(epochs, accu, 'r', label='accuracy') \n    plt.plot(epochs, val_accu, 'b', label='val_accuracy') \n    plt.title('accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('accuracy')\n    plt.legend()\n    plt.savefig('accuracy.png')\n    plt.show()\n    #plt.imshow(mpimg.imread('./accuracy.png'))\n    '''","metadata":{"execution":{"iopub.status.busy":"2023-02-16T20:15:23.240949Z","iopub.execute_input":"2023-02-16T20:15:23.241598Z","iopub.status.idle":"2023-02-16T20:15:23.258193Z","shell.execute_reply.started":"2023-02-16T20:15:23.241558Z","shell.execute_reply":"2023-02-16T20:15:23.256815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # testing part****","metadata":{}},{"cell_type":"code","source":"os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nimport numpy as np\nimport cv2\nimport pandas as pd\nfrom glob import glob\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras.utils import CustomObjectScope\nfrom sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n#import dice_coef, iou\n#import load_data\n\nH = 1024\nW = 1024\n\n\ndef create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\n\ndef read_image(path):\n    x = cv2.imread(path, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (W, H))\n    ori_x = x\n    x = x / 255.0\n    x = x.astype(np.float32)\n    x = np.expand_dims(x, axis=0)  ## (1, 256, 256, 3)\n    return ori_x, x\n\n\ndef read_mask(path):\n    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, (W, H))\n    ori_x = x\n    x = x / 255.0\n    x = x > 0.5\n    x = x.astype(np.int32)\n    return ori_x, x\n\n\ndef save_result(ori_x, ori_y, y_pred, save_path):\n    line = np.ones((H, 10, 3)) * 255\n\n    ori_y = np.expand_dims(ori_y, axis=-1)  ## (256, 256, 1)\n    ori_y = np.concatenate([ori_y, ori_y, ori_y], axis=-1)  ## (256, 256, 3)\n\n    y_pred = np.expand_dims(y_pred, axis=-1)\n    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1) * 255.0\n\n    cat_images = np.concatenate([ori_x, line, ori_y, line, y_pred], axis=1)\n    cv2.imwrite(save_path, cat_images)\nif __name__ == \"__main__\":\n    create_dir(\"results2\")\n\n    \"\"\" Load Model \"\"\"\n    with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef}):\n        model = tf.keras.models.load_model(\"/kaggle/input/isr-model1/model10.h5\")\n        #model.summary()\n\n    \"\"\" Dataset \"\"\"\n    dataset_path = \"/kaggle/working/BNS_1024_test\"\n    #dataset_path = \"/imagesToAugment/images\"\n    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(dataset_path)\n\n    \"\"\" Prediction and metrics values \"\"\"\n    SCORE = []\n    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n        name = x.split(\"/\")[-1]\n\n        \"\"\" Reading the image and mask \"\"\"\n        ori_x, x = read_image(x)\n        ori_y, y = read_mask(y)\n\n        \"\"\" Prediction \"\"\"\n        y_pred = model.predict(x)[0] > 0.5\n        y_pred = np.squeeze(y_pred, axis=-1)\n        y_pred = y_pred.astype(np.int32)\n\n        save_path = f\"results2/{name}\"\n        save_result(ori_x, ori_y, y_pred, save_path)\n\n        \"\"\" Flattening the numpy arrays. \"\"\"\n        y = y.flatten()\n        y_pred = y_pred.flatten()\n\n        \"\"\" Calculating metrics values \"\"\"\n        acc_value = accuracy_score(y, y_pred)\n        f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n        jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n        recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n        precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n        SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n\n    \"\"\" Metrics values \"\"\"\n    score = [s[1:] for s in SCORE]\n    score = np.mean(score, axis=0)\n    print(f\"Accuracy: {score[0]:0.5f}\")\n    print(f\"F1: {score[1]:0.5f}\")\n    print(f\"Jaccard: {score[2]:0.5f}\")\n    print(f\"Recall: {score[3]:0.5f}\")\n    print(f\"Precision: {score[4]:0.5f}\")\n\n ","metadata":{"execution":{"iopub.status.busy":"2023-06-23T17:55:08.145824Z","iopub.execute_input":"2023-06-23T17:55:08.146205Z","iopub.status.idle":"2023-06-23T18:02:08.257534Z","shell.execute_reply.started":"2023-06-23T17:55:08.146169Z","shell.execute_reply":"2023-06-23T18:02:08.256241Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 300/300 [06:53<00:00,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.90926\nF1: 0.23084\nJaccard: 0.14107\nRecall: 0.16279\nPrecision: 0.72053\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##################################\"\"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##################################\"\"","metadata":{}},{"cell_type":"code","source":"'''\nimport cv2\nimport glob\nimport matplotlib.pyplot as plt\n    \npath=\"./results/*.jpg\"\n\nimages=[cv2.imread(image) for image in glob.glob(path)]\nfig=plt.figure()\nfor i in range(len(images)):\n    #plt.subplot(5,5,i+1)\n    plt.imshow(images[i])\n    plt.show()'''","metadata":{"execution":{"iopub.status.busy":"2023-02-16T20:15:23.274552Z","iopub.execute_input":"2023-02-16T20:15:23.274911Z","iopub.status.idle":"2023-02-16T20:15:23.286704Z","shell.execute_reply.started":"2023-02-16T20:15:23.274877Z","shell.execute_reply":"2023-02-16T20:15:23.285589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''!zip -r ./file.zip ./results '''","metadata":{"execution":{"iopub.status.busy":"2023-02-16T20:15:23.288335Z","iopub.execute_input":"2023-02-16T20:15:23.289349Z","iopub.status.idle":"2023-02-16T20:15:23.297215Z","shell.execute_reply.started":"2023-02-16T20:15:23.289307Z","shell.execute_reply":"2023-02-16T20:15:23.29608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''from IPython.display import FileLink\nFileLink(r'file.zip')'''","metadata":{"execution":{"iopub.status.busy":"2023-02-16T20:15:23.298769Z","iopub.execute_input":"2023-02-16T20:15:23.29932Z","iopub.status.idle":"2023-02-16T20:15:23.307374Z","shell.execute_reply.started":"2023-02-16T20:15:23.299285Z","shell.execute_reply":"2023-02-16T20:15:23.306186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}